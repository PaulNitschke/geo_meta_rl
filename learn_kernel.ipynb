{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.utils import load_replay_buffer\n",
    "\n",
    "TASK_NAME=\"sac_circle_rotation_task_0\"\n",
    "N_SAMPLES:int=100_000\n",
    "KERNEL_DIM=1\n",
    "EPSILON_BALL = 0.025\n",
    "EPSILON_LEVEL_SET = 0.0025\n",
    "\n",
    "LEARN_KERNEL_BASES: bool=True\n",
    "\n",
    "\n",
    "replay_buffer_name:str=TASK_NAME+\"_replay_buffer.pkl\"\n",
    "kernel_bases_name:str=TASK_NAME+\"_kernel_bases.pkl\"\n",
    "\n",
    "\n",
    "replay_buffer_task_1= load_replay_buffer(replay_buffer_name, N_steps=N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise kernel bases of reward function\n",
    "\n",
    "- We have $R(p)=n$ where $p=(s,a)$ and $n$ is the real-valued reward value.\n",
    "- Learn the component of $G$ that acts on $S$ and the component of $G$ that acts on $A$ independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/learning/symmetry_discovery/differential/kernel_approx.py:32: UserWarning: TODO: Dimension of kernel should be actively inferred, not passed as an argument.\n",
      "  warnings.warn(\"TODO: Dimension of kernel should be actively inferred, not passed as an argument.\")\n",
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/learning/symmetry_discovery/differential/kernel_approx.py:62: UserWarning: Kernel Approximation currently only supports real-valued functions.\n",
      "  warnings.warn(\"Kernel Approximation currently only supports real-valued functions.\")\n",
      "INFO:root:Computing neighborhood of samples via kdtree...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ps:  torch.Size([100000, 2])  (should be (N_steps, |S|))\n",
      "Shape of ns:  torch.Size([100000])  (should be (N_steps))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locate samples in neighborhood...: 100%|██████████| 100000/100000 [00:32<00:00, 3073.26it/s]\n",
      "Compute pointwise kernel samples...: 100%|██████████| 100000/100000 [00:09<00:00, 10002.81it/s]\n",
      "Compute Point-Wise Bases via PCA...: 100%|██████████| 100000/100000 [00:09<00:00, 10113.73it/s]\n",
      "INFO:root:Computed kernel bases from:\n",
      "  - multiple tangent vectors for 92.94% of samples (good)\n",
      "  - one tangent vector for 2.01% of samples (okay)\n",
      "  - no tangent vector for 5.05% of samples (not good, no basis).\n"
     ]
    }
   ],
   "source": [
    "from src.learning.symmetry_discovery.differential.kernel_approx import pointwise_kernel_approx\n",
    "\n",
    "\n",
    "ps=replay_buffer_task_1[\"observations\"]\n",
    "ns=replay_buffer_task_1[\"rewards\"]\n",
    "\n",
    "print(\"Shape of ps: \", ps.shape, \" (should be (N_steps, |S|))\")\n",
    "print(\"Shape of ns: \", ns.shape, \" (should be (N_steps))\")\n",
    "\n",
    "if LEARN_KERNEL_BASES:\n",
    "    kernel_samples=pointwise_kernel_approx(p=ps, n=ns, kernel_dim=KERNEL_DIM, epsilon_ball=EPSILON_BALL, epsilon_level_set=EPSILON_LEVEL_SET)\n",
    "    with open(kernel_bases_name, 'wb') as f:\n",
    "        pickle.dump(kernel_samples, f)\n",
    "else:\n",
    "    with open(kernel_bases_name, 'rb') as f:\n",
    "        kernel_samples = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Grassman Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def kernel_weights(p_query, ps, bandwidth):\n",
    "    # Gaussian kernel weights between p_query and each p_i in ps\n",
    "    dists = torch.norm(ps - p_query, dim=1)\n",
    "    weights = torch.exp(-dists**2 / (2 * bandwidth**2))\n",
    "    weights = weights / weights.sum()\n",
    "    return weights\n",
    "\n",
    "def log_map_grassmann(V_ref, V):\n",
    "    # V_ref: (d, k), V: (d, k), both orthonormal\n",
    "    M = V_ref.T @ V  # (k, k)\n",
    "    U, S, Vt = torch.linalg.svd(M)\n",
    "    # Numerical stability for arccos\n",
    "    S_clamped = torch.clamp(S, -1.0 + 1e-6, 1.0 - 1e-6)\n",
    "    Theta = torch.arccos(S_clamped)\n",
    "    sin_Theta = torch.sin(Theta)\n",
    "    sin_Theta[sin_Theta == 0] = 1e-6\n",
    "    A = (V - V_ref @ M) @ torch.diag(Theta / sin_Theta)\n",
    "    return A  # Tangent vector in T_{V_ref} Gr(k, d)\n",
    "\n",
    "def exp_map_grassmann(V_ref, A):\n",
    "    # A: tangent vector in T_{V_ref} Gr(k, d), shape (d, k)\n",
    "    U, S, Vt = torch.linalg.svd(A, full_matrices=False)\n",
    "    Theta = S\n",
    "    sin_Theta = torch.sin(Theta)\n",
    "    cos_Theta = torch.cos(Theta)\n",
    "    term1 = V_ref @ (Vt.T @ torch.diag(cos_Theta) @ Vt)\n",
    "    term2 = U @ torch.diag(sin_Theta) @ Vt\n",
    "    V_new = term1 + term2\n",
    "    return torch.linalg.qr(V_new, mode='reduced').Q  # Ensure orthonormal output\n",
    "\n",
    "def smooth_subspace(p_query, ps, kernel_samples, bandwidth):\n",
    "    N = ps.shape[0]\n",
    "    \n",
    "    # Select nearest kernel_samples indices\n",
    "    available_indices = list(kernel_samples.keys())\n",
    "    V_bases = [kernel_samples[i] for i in available_indices]\n",
    "    ps_subset = ps[available_indices]  # (n_subset, d)\n",
    "\n",
    "    # Kernel weights\n",
    "    weights = kernel_weights(p_query, ps_subset, bandwidth)  # (n_subset,)\n",
    "    \n",
    "    # Reference basis (e.g., nearest neighbor)\n",
    "    ref_idx = torch.argmin(torch.norm(ps_subset - p_query, dim=1)).item()\n",
    "    V_ref = V_bases[ref_idx]  # (d, k)\n",
    "    \n",
    "    # Compute log maps and weighted sum\n",
    "    tangent_sum = torch.zeros_like(V_ref)\n",
    "    for i, V_i in enumerate(V_bases):\n",
    "        W = log_map_grassmann(V_ref, V_i)  # (d, k)\n",
    "        tangent_sum += weights[i] * W\n",
    "    \n",
    "    # Project back using exp map\n",
    "    V_smooth = exp_map_grassmann(V_ref, tangent_sum)  # (d, k)\n",
    "    return V_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cm/rfx_nb1x16zcxk4frrwkp_1r0000gn/T/ipykernel_15860/1011799044.py:13: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /private/var/folders/c_/qfmhj66j0tn016nkx_th4hxm0000gp/T/abs_290u7eqnqq/croot/pytorch-select_1730848721858/work/aten/src/ATen/native/TensorShape.cpp:3679.)\n",
      "  M = V_ref.T @ V  # (k, k)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linalg.svd: The input tensor A must have at least 2 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m p_query\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.7\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m V_smooth \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_subspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (d, k)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m, in \u001b[0;36msmooth_subspace\u001b[0;34m(p_query, ps, kernel_samples, bandwidth)\u001b[0m\n\u001b[1;32m     50\u001b[0m tangent_sum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(V_ref)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, V_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(V_bases):\n\u001b[0;32m---> 52\u001b[0m     W \u001b[38;5;241m=\u001b[39m \u001b[43mlog_map_grassmann\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_i\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (d, k)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     tangent_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[i] \u001b[38;5;241m*\u001b[39m W\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Project back using exp map\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mlog_map_grassmann\u001b[0;34m(V_ref, V)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_map_grassmann\u001b[39m(V_ref, V):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# V_ref: (d, k), V: (d, k), both orthonormal\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     M \u001b[38;5;241m=\u001b[39m V_ref\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m V  \u001b[38;5;66;03m# (k, k)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Numerical stability for arccos\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     S_clamped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(S, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linalg.svd: The input tensor A must have at least 2 dimensions."
     ]
    }
   ],
   "source": [
    "p_query=torch.tensor([0.5, 0.7])\n",
    "\n",
    "V_smooth = smooth_subspace(p_query, ps, kernel_samples, bandwidth=0.25)  # (d, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/learning/symmetry_discovery/differential/diff_generator.py:195: UserWarning: TODO: only learns linear Kernel distributions.\n",
      "  warnings.warn(\"TODO: only learns linear Kernel distributions.\")\n",
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/learning/symmetry_discovery/differential/diff_generator.py:196: UserWarning: TODO: Implement early stopping in Kernel learning.\n",
      "  warnings.warn(\"TODO: Implement early stopping in Kernel learning.\")\n",
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/learning/symmetry_discovery/differential/diff_generator.py:58: UserWarning: TODO: Differential Generator is not Normalized During Training\n",
      "  warnings.warn(\"TODO: Differential Generator is not Normalized During Training\")\n",
      "Loss: 2.0795e+02: 100%|██████████| 10000/10000 [00:21<00:00, 470.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0462, -0.0700],\n",
       "         [-0.6525,  0.9691]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "from src.learning.symmetry_discovery.differential.diff_generator import DiffGenerator\n",
    "\n",
    "g_0=th.randn(KERNEL_DIM, ps.shape[1], ps.shape[1], requires_grad=True)\n",
    "optimizer= th.optim.Adam([g_0], lr=5e-5)\n",
    "N_steps=10_000\n",
    "\n",
    "linear_kernel=DiffGenerator(g_0=g_0, p=ps, bases=kernel_samples, n_steps=N_steps, optimizer=optimizer, batch_size=256)\n",
    "linear_kernel.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0775,  0.2187],\n",
       "         [-0.5813, -0.4310]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_kernel.g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_geo_meta_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

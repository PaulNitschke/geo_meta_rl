{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/utils.py:100: UserWarning: Replay buffer contains more samples than selected.\n",
      "  warnings.warn(\"Replay buffer contains more samples than selected.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_0_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_1_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_2_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_3_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from src.learning.symmetry.hereditary_geometry_discovery import HereditaryGeometryDiscovery\n",
    "from argparser import get_argparser, get_non_default_args\n",
    "from src.utils import load_replay_buffer_and_kernel, Affine2D\n",
    "\n",
    "FOLDER_NAME: str=\"data/local/experiment/circle_rotation\"\n",
    "TASK_NAMES=[\"sac_circle_rotation_task_0\", \"sac_circle_rotation_task_1\", \"sac_circle_rotation_task_2\", \"sac_circle_rotation_task_3\"]\n",
    "\n",
    "parser = get_argparser()\n",
    "args = parser.parse_args([\"--log_wandb\", \"false\"])\n",
    "\n",
    "\n",
    "train_goal_locations=[\n",
    "    {'goal': torch.tensor([-0.70506063,  0.70914702])},\n",
    "    {'goal': torch.tensor([ 0.95243384, -0.30474544])},\n",
    "    {'goal': torch.tensor([-0.11289421, -0.99360701])},\n",
    "    {'goal': torch.tensor([-0.81394263, -0.58094525])}]\n",
    "\n",
    "LOAD_WHAT:str=\"next_observations\"\n",
    "N_SAMPLES=50_000\n",
    "ENCODER=Affine2D(input_dim=2, output_dim=2)\n",
    "DECODER=Affine2D(input_dim=2, output_dim=2)\n",
    "ORACLE_ENCODER=Affine2D(input_dim=2, output_dim=2)\n",
    "ORACLE_DECODER=Affine2D(input_dim=2, output_dim=2)\n",
    "\n",
    "ORACLE_GENERATOR=torch.tensor([[0, -1], [1,0]], dtype=torch.float32, requires_grad=False).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ORACLE_ENCODER.linear.weight.copy_(torch.eye(2))\n",
    "    ORACLE_DECODER.linear.weight.copy_(torch.eye(2))\n",
    "    ORACLE_ENCODER.linear.bias.copy_(-train_goal_locations[0][\"goal\"])\n",
    "    ORACLE_DECODER.linear.bias.copy_(train_goal_locations[0][\"goal\"])\n",
    "\n",
    "# 1. Load replay buffers and frame estimators.\n",
    "tasks_ps, tasks_frameestimators=[], []\n",
    "for task_name in TASK_NAMES:\n",
    "    ps, frameestimator = load_replay_buffer_and_kernel(task_name, LOAD_WHAT, args.kernel_dim, N_SAMPLES, FOLDER_NAME)\n",
    "    tasks_ps.append(ps)\n",
    "    tasks_frameestimators.append(frameestimator)\n",
    "\n",
    "\n",
    "\n",
    "oracle_generator=ORACLE_GENERATOR if not args.learn_generator else None\n",
    "\n",
    "\n",
    "# 3. Train.\n",
    "her_geo_dis=HereditaryGeometryDiscovery(tasks_ps=tasks_ps,tasks_frameestimators=tasks_frameestimators, \n",
    "                                        oracle_generator=oracle_generator, encoder=ENCODER, decoder=DECODER,\n",
    "\n",
    "                                        kernel_dim=args.kernel_dim, n_steps_pretrain_geo=args.n_steps_pretrain_geo,\n",
    "                                        update_chart_every_n_steps=args.update_chart_every_n_steps, eval_span_how=args.eval_span_how,\n",
    "                                        log_lg_inits_how=args.log_lg_inits_how,\n",
    "\n",
    "                                        batch_size=args.batch_size, \n",
    "                                        lr_lgs=args.lr_lgs,lr_gen=args.lr_gen,lr_chart=args.lr_chart,\n",
    "                                        lasso_coef_lgs=args.lasso_coef_lgs, lasso_coef_generator=args.lasso_coef_generator, lasso_coef_encoder_decoder=args.lasso_coef_encoder_decoder,\n",
    "                                        \n",
    "                                        seed=args.seed, log_wandb=args.log_wandb, log_wandb_gradients=args.log_wandb_gradients, save_every=args.save_every,\n",
    "                                        bandwidth=args.bandwidth,\n",
    "\n",
    "                                        task_specifications=train_goal_locations, \n",
    "                                        use_oracle_rotation_kernel=args.use_oracle_rotation_kernel,\n",
    "                                        save_dir=None,\n",
    "\n",
    "                                        eval_sym_in_follower=args.eval_sym_in_follower,\n",
    "                                        oracle_encoder=ORACLE_ENCODER, oracle_decoder=ORACLE_DECODER\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_vector_field(p_batch: torch.tensor, center)->torch.tensor:\n",
    "    \"\"\"Returns kernel samples at batched points p from a task.\"\"\"\n",
    "\n",
    "    _generator=torch.tensor([[0, -1], [1,0]], requires_grad=False, dtype=torch.float32).unsqueeze(0)\n",
    "    projected_state = p_batch-center\n",
    "    gradients = torch.einsum(\"dmn, bn->bdm\", _generator, projected_state)\n",
    "    return gradients/gradients.norm(dim=-1, keepdim=True)\n",
    "\n",
    "ps = torch.randn(100, 2)\n",
    "center = train_goal_locations[0][\"goal\"]\n",
    "gradients = rotation_vector_field(ps, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_geo_meta_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulnitschke/Desktop/projects/geo_meta_rl/src/utils.py:68: UserWarning: Replay buffer contains more samples than selected.\n",
      "  warnings.warn(\"Replay buffer contains more samples than selected.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_0_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_1_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_2_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded next_observations from data/local/experiment/circle_rotation/sac_circle_rotation_task_3_replay_buffer.pkl with shape torch.Size([100000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Setup kernel frame evaluation.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "from src.utils import load_replay_buffer\n",
    "from src.learning.symmetry_discovery.differential.kernel_approx import KernelFrameEstimator\n",
    "\n",
    "FOLDER_NAME: str=\"data/local/experiment/circle_rotation\"\n",
    "TASK_NAMES=[\"sac_circle_rotation_task_0\", \"sac_circle_rotation_task_1\", \"sac_circle_rotation_task_2\", \"sac_circle_rotation_task_3\"]\n",
    "\n",
    "LOAD_WHAT:str=\"next_observations\"\n",
    "KERNEL_DIM=1\n",
    "N_SAMPLES=50_000\n",
    "\n",
    "\n",
    "def load_replay_buffer_and_kernel(task_name:str, load_what:str, kernel_dim: int, n_samples:int, folder_name):\n",
    "    \"\"\"Loads samples and kernel evaluator of a task.\"\"\"\n",
    "\n",
    "    assert load_what in [\"observations\", \"actions\", \"next_observations\"], \"Learn hereditary geometry for states, actions or next states.\"\n",
    "\n",
    "    buffer_name= os.path.join(folder_name, f\"{task_name}_replay_buffer.pkl\")\n",
    "    kernel_name= os.path.join(folder_name, f\"{task_name}_kernel_bases.pkl\")\n",
    "\n",
    "\n",
    "    buffer= load_replay_buffer(buffer_name, N_steps=n_samples)\n",
    "    ps=buffer[load_what]\n",
    "    print(f\"Loaded {load_what} from {buffer_name} with shape {ps.shape}\")\n",
    "\n",
    "    # Load kernel bases\n",
    "    frameestimator=KernelFrameEstimator(ps=ps, kernel_dim=kernel_dim)\n",
    "    with open(kernel_name, 'rb') as f:\n",
    "        kernel_samples = pickle.load(f)\n",
    "    frameestimator.set_frame(frame=kernel_samples)\n",
    "\n",
    "    return ps, frameestimator\n",
    "\n",
    "tasks_ps, tasks_frameestimators=[], []\n",
    "for task_name in TASK_NAMES:\n",
    "    ps, frameestimator = load_replay_buffer_and_kernel(task_name, LOAD_WHAT, KERNEL_DIM, N_SAMPLES, FOLDER_NAME)\n",
    "    tasks_ps.append(ps)\n",
    "    tasks_frameestimators.append(frameestimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from src.learning.symmetry_discovery.differential.hereditary_geometry_discovery import HereditaryGeometryDiscovery\n",
    "ORACLE_GENERATOR=torch.tensor([[0, -1], [1,0]], dtype=torch.float32, requires_grad=False).unsqueeze(0)\n",
    "train_goal_locations=[\n",
    "    {'goal': torch.tensor([-0.70506063,  0.70914702])},\n",
    " {'goal': torch.tensor([ 0.95243384, -0.30474544])},\n",
    " {'goal': torch.tensor([-0.11289421, -0.99360701])},\n",
    " {'goal': torch.tensor([-0.81394263, -0.58094525])}]\n",
    "\n",
    "class Affine2D(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "SEED=42\n",
    "LEARN_LEFT_ACTIONS=False\n",
    "LEARN_GENERATOR=False\n",
    "\n",
    "ENCODER=Affine2D(input_dim=2, output_dim=2)\n",
    "DECODER=Affine2D(input_dim=2, output_dim=2)\n",
    "\n",
    "def identity_initialization_encoder_decoder(encoder: callable, \n",
    "                                            decoder: callable, \n",
    "                                            tasks_ps: list,\n",
    "                                            n_steps: int = 5_000):\n",
    "    \"\"\"Initializes encoder and decoder to identity map on all tasks via gradient flow.\"\"\"\n",
    "\n",
    "    def stack_samples(ps: list):\n",
    "        \"\"\"Stacks samples from all tasks into a single tensor.\"\"\"\n",
    "        _n_tasks = len(tasks_ps)\n",
    "        _n_samples_per_task, ambient_dim = tasks_ps[0].shape\n",
    "        ps = torch.empty([_n_tasks, _n_samples_per_task, ambient_dim], dtype=torch.float32)\n",
    "        for i, task_ps in enumerate(tasks_ps):\n",
    "            ps[i] = task_ps\n",
    "        return ps.reshape([-1, ambient_dim])\n",
    "\n",
    "    ps = stack_samples(tasks_ps)\n",
    "    print(f\"Stacked samples shape: {ps.shape}\")\n",
    "\n",
    "    encoder_opt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "    decoder_opt = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "    pbar = tqdm(range(n_steps), desc=\"Initializing to identity\")\n",
    "\n",
    "    for step in pbar:\n",
    "        encoder_opt.zero_grad()\n",
    "        decoder_opt.zero_grad()\n",
    "\n",
    "        encoded_ps = encoder(ps)\n",
    "        decoded_ps = decoder(ps)\n",
    "\n",
    "        enc_loss = torch.nn.functional.mse_loss(encoded_ps, ps)\n",
    "        dec_loss = torch.nn.functional.mse_loss(decoded_ps, ps)\n",
    "        total_loss = enc_loss + dec_loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        encoder_opt.step()\n",
    "        decoder_opt.step()\n",
    "\n",
    "        if step%100==0:\n",
    "            pbar.set_postfix({\n",
    "                \"enc_loss\": f\"{enc_loss.item():.4e}\",\n",
    "                \"dec_loss\": f\"{dec_loss.item():.4e}\",\n",
    "                \"total\": f\"{total_loss.item():.4e}\"\n",
    "            })\n",
    "    return encoder, decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked samples shape: torch.Size([400000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing to identity: 100%|██████████| 5000/5000 [00:18<00:00, 268.43it/s, enc_loss=9.7672e-14, dec_loss=1.4319e-12, total=1.5295e-12]\n"
     ]
    }
   ],
   "source": [
    "encoder_init, decoder_init= identity_initialization_encoder_decoder(encoder=ENCODER, decoder=DECODER, tasks_ps=tasks_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_geo_dis=HereditaryGeometryDiscovery(tasks_ps=tasks_ps,\n",
    "                                        tasks_frameestimators=tasks_frameestimators, \n",
    "                                        kernel_dim=KERNEL_DIM, \n",
    "                                        batch_size=128, \n",
    "                                        seed=SEED, \n",
    "                                        bandwidth=0.5,\n",
    "                                        learn_left_actions=False,\n",
    "                                        learn_encoder_decoder=True,\n",
    "                                        task_specifications=train_goal_locations,\n",
    "                                        learn_left_actions=LEARN_LEFT_ACTIONS,\n",
    "                                        learn_generator=LEARN_GENERATOR,\n",
    "                                        oracle_generator=ORACLE_GENERATOR,\n",
    "                                        encoder=encoder_init,\n",
    "                                        decoder=decoder_init)\n",
    "her_geo_dis.optimize(n_steps=250_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_geo_meta_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

2025-01-08 09:33:42 | [CL_point_env] Logging to /Users/paulnitschke/Desktop/projects/geo_meta_rl/data/local/experiment/CL_point_env_28


Failed to import TF-Keras. Please note that TF-Keras is not installed by default when you install TensorFlow Probability. This is so that JAX-only users do not have to install TensorFlow or TF-Keras. To use TensorFlow Probability with TensorFlow, please install the tf-keras or tf-keras-nightly package.
This can be be done through installing the tensorflow-probability[tf] extra.
/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.
  warnings.warn(


2025-01-08 09:33:42 | [CL_point_env] Obtaining samples...
/Users/paulnitschke/miniconda3/envs/env_geo_meta_rl/lib/python3.9/site-packages/torch/distributions/distribution.py:53: UserWarning: <class 'garage.torch.distributions.tanh_normal.TanhNormal'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.
  warnings.warn(
/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/_dtypes.py:1051: UserWarning: Observation array([0., 0., 2.]) is outside observation_space Box(-inf, inf, (3,), float32)
  warnings.warn(
2025-01-08 09:33:45 | [CL_point_env] epoch #0 | Pre-Training Encoder...
2025-01-08 09:33:45 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[1.0000, 0.9984],
        [0.9984, 1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:00 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9989],
        [-0.9989,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:00 | [CL_point_env] epoch #0 | Pre-Training Encoder Done...
2025-01-08 09:34:00 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9992],
        [-0.9992,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:00 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9992],
        [-0.9992,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:00 | [CL_point_env] epoch #0 | Training...
2025-01-08 09:34:01 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9995],
        [-0.9995,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:01 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9995],
        [-0.9995,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:01 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0579126
PolicyTraining/MeanQ1Vals      -22.432
PolicyTraining/MeanQ2Vals      -22.432
PolicyTraining/MeanVVals        -4.44753
PolicyTraining/PolicyLoss       21.2361
PolicyTraining/QfLoss           13.0887
PolicyTraining/VfLoss          294.253
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0579126
PolicyTraining/MeanQ1Vals      -22.432
PolicyTraining/MeanQ2Vals      -22.432
PolicyTraining/MeanVVals        -4.44753
PolicyTraining/PolicyLoss       21.2361
PolicyTraining/QfLoss           13.0887
PolicyTraining/VfLoss          294.253
-----------------------------  -----------
2025-01-08 09:34:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9996],
        [-0.9996,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9996],
        [-0.9996,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:21 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578983
PolicyTraining/MeanQ1Vals      -22.4682
PolicyTraining/MeanQ2Vals      -22.4682
PolicyTraining/MeanVVals       -20.0202
PolicyTraining/PolicyLoss       21.225
PolicyTraining/QfLoss            5.27026
PolicyTraining/VfLoss            2.12084
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578983
PolicyTraining/MeanQ1Vals      -22.4682
PolicyTraining/MeanQ2Vals      -22.4682
PolicyTraining/MeanVVals       -20.0202
PolicyTraining/PolicyLoss       21.225
PolicyTraining/QfLoss            5.27026
PolicyTraining/VfLoss            2.12084
-----------------------------  -----------
2025-01-08 09:34:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9997],
        [-0.9997,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9997],
        [-0.9997,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:34:41 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0579034
PolicyTraining/MeanQ1Vals      -24.3559
PolicyTraining/MeanQ2Vals      -24.3559
PolicyTraining/MeanVVals       -23.0708
PolicyTraining/PolicyLoss       23.1091
PolicyTraining/QfLoss            1.45557
PolicyTraining/VfLoss            0.999558
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0579034
PolicyTraining/MeanQ1Vals      -24.3559
PolicyTraining/MeanQ2Vals      -24.3559
PolicyTraining/MeanVVals       -23.0708
PolicyTraining/PolicyLoss       23.1091
PolicyTraining/QfLoss            1.45557
PolicyTraining/VfLoss            0.999558
-----------------------------  -----------
2025-01-08 09:35:01 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:01 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:01 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578935
PolicyTraining/MeanQ1Vals      -26.7977
PolicyTraining/MeanQ2Vals      -26.7977
PolicyTraining/MeanVVals       -25.6567
PolicyTraining/PolicyLoss       25.6114
PolicyTraining/QfLoss            0.485083
PolicyTraining/VfLoss            0.89481
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578935
PolicyTraining/MeanQ1Vals      -26.7977
PolicyTraining/MeanQ2Vals      -26.7977
PolicyTraining/MeanVVals       -25.6567
PolicyTraining/PolicyLoss       25.6114
PolicyTraining/QfLoss            0.485083
PolicyTraining/VfLoss            0.89481
-----------------------------  -----------
2025-01-08 09:35:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9998],
        [-0.9998,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9998],
        [-0.9998,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:21 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578926
PolicyTraining/MeanQ1Vals      -30.7752
PolicyTraining/MeanQ2Vals      -30.7752
PolicyTraining/MeanVVals       -29.6161
PolicyTraining/PolicyLoss       29.6354
PolicyTraining/QfLoss            0.295163
PolicyTraining/VfLoss            0.113008
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578926
PolicyTraining/MeanQ1Vals      -30.7752
PolicyTraining/MeanQ2Vals      -30.7752
PolicyTraining/MeanVVals       -29.6161
PolicyTraining/PolicyLoss       29.6354
PolicyTraining/QfLoss            0.295163
PolicyTraining/VfLoss            0.113008
-----------------------------  -----------
2025-01-08 09:35:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:35:41 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578928
PolicyTraining/MeanQ1Vals      -33.8309
PolicyTraining/MeanQ2Vals      -33.8309
PolicyTraining/MeanVVals       -32.7075
PolicyTraining/PolicyLoss       32.7265
PolicyTraining/QfLoss            0.208861
PolicyTraining/VfLoss            0.0758786
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578928
PolicyTraining/MeanQ1Vals      -33.8309
PolicyTraining/MeanQ2Vals      -33.8309
PolicyTraining/MeanVVals       -32.7075
PolicyTraining/PolicyLoss       32.7265
PolicyTraining/QfLoss            0.208861
PolicyTraining/VfLoss            0.0758786
-----------------------------  -----------
2025-01-08 09:36:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:02 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578884
PolicyTraining/MeanQ1Vals      -34.8297
PolicyTraining/MeanQ2Vals      -34.8297
PolicyTraining/MeanVVals       -33.7868
PolicyTraining/PolicyLoss       33.7824
PolicyTraining/QfLoss            0.136801
PolicyTraining/VfLoss            0.0723519
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578884
PolicyTraining/MeanQ1Vals      -34.8297
PolicyTraining/MeanQ2Vals      -34.8297
PolicyTraining/MeanVVals       -33.7868
PolicyTraining/PolicyLoss       33.7824
PolicyTraining/QfLoss            0.136801
PolicyTraining/VfLoss            0.0723519
-----------------------------  -----------
2025-01-08 09:36:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:21 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -0.9999],
        [-0.9999,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:21 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578893
PolicyTraining/MeanQ1Vals      -39.3191
PolicyTraining/MeanQ2Vals      -39.3191
PolicyTraining/MeanVVals       -38.3398
PolicyTraining/PolicyLoss       38.3496
PolicyTraining/QfLoss            0.105255
PolicyTraining/VfLoss            0.0640955
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578893
PolicyTraining/MeanQ1Vals      -39.3191
PolicyTraining/MeanQ2Vals      -39.3191
PolicyTraining/MeanVVals       -38.3398
PolicyTraining/PolicyLoss       38.3496
PolicyTraining/QfLoss            0.105255
PolicyTraining/VfLoss            0.0640955
-----------------------------  -----------
2025-01-08 09:36:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:41 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:36:41 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578889
PolicyTraining/MeanQ1Vals      -41.9295
PolicyTraining/MeanQ2Vals      -41.9295
PolicyTraining/MeanVVals       -41.0283
PolicyTraining/PolicyLoss       41.0142
PolicyTraining/QfLoss            0.10244
PolicyTraining/VfLoss            0.0648677
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578889
PolicyTraining/MeanQ1Vals      -41.9295
PolicyTraining/MeanQ2Vals      -41.9295
PolicyTraining/MeanVVals       -41.0283
PolicyTraining/PolicyLoss       41.0142
PolicyTraining/QfLoss            0.10244
PolicyTraining/VfLoss            0.0648677
-----------------------------  -----------
2025-01-08 09:37:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:02 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -45.1105
PolicyTraining/MeanQ2Vals      -45.1105
PolicyTraining/MeanVVals       -44.2157
PolicyTraining/PolicyLoss       44.2664
PolicyTraining/QfLoss            0.0868079
PolicyTraining/VfLoss            0.0710359
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -45.1105
PolicyTraining/MeanQ2Vals      -45.1105
PolicyTraining/MeanVVals       -44.2157
PolicyTraining/PolicyLoss       44.2664
PolicyTraining/QfLoss            0.0868079
PolicyTraining/VfLoss            0.0710359
-----------------------------  -----------
2025-01-08 09:37:22 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:22 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:22 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578875
PolicyTraining/MeanQ1Vals      -51.35
PolicyTraining/MeanQ2Vals      -51.35
PolicyTraining/MeanVVals       -50.6032
PolicyTraining/PolicyLoss       50.6139
PolicyTraining/QfLoss            0.0782334
PolicyTraining/VfLoss            0.0590598
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578875
PolicyTraining/MeanQ1Vals      -51.35
PolicyTraining/MeanQ2Vals      -51.35
PolicyTraining/MeanVVals       -50.6032
PolicyTraining/PolicyLoss       50.6139
PolicyTraining/QfLoss            0.0782334
PolicyTraining/VfLoss            0.0590598
-----------------------------  -----------
2025-01-08 09:37:42 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:42 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:37:42 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -55.1313
PolicyTraining/MeanQ2Vals      -55.1313
PolicyTraining/MeanVVals       -54.4172
PolicyTraining/PolicyLoss       54.4564
PolicyTraining/QfLoss            0.0725208
PolicyTraining/VfLoss            0.069953
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -55.1313
PolicyTraining/MeanQ2Vals      -55.1313
PolicyTraining/MeanVVals       -54.4172
PolicyTraining/PolicyLoss       54.4564
PolicyTraining/QfLoss            0.0725208
PolicyTraining/VfLoss            0.069953
-----------------------------  -----------
2025-01-08 09:38:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:02 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:02 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578858
PolicyTraining/MeanQ1Vals      -56.8077
PolicyTraining/MeanQ2Vals      -56.8077
PolicyTraining/MeanVVals       -56.3087
PolicyTraining/PolicyLoss       56.2309
PolicyTraining/QfLoss            0.0737983
PolicyTraining/VfLoss            0.0646639
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578858
PolicyTraining/MeanQ1Vals      -56.8077
PolicyTraining/MeanQ2Vals      -56.8077
PolicyTraining/MeanVVals       -56.3087
PolicyTraining/PolicyLoss       56.2309
PolicyTraining/QfLoss            0.0737983
PolicyTraining/VfLoss            0.0646639
-----------------------------  -----------
2025-01-08 09:38:22 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:22 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:22 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -59.0754
PolicyTraining/MeanQ2Vals      -59.0754
PolicyTraining/MeanVVals       -58.5411
PolicyTraining/PolicyLoss       58.5598
PolicyTraining/QfLoss            0.0779131
PolicyTraining/VfLoss            0.0692206
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578864
PolicyTraining/MeanQ1Vals      -59.0754
PolicyTraining/MeanQ2Vals      -59.0754
PolicyTraining/MeanVVals       -58.5411
PolicyTraining/PolicyLoss       58.5598
PolicyTraining/QfLoss            0.0779131
PolicyTraining/VfLoss            0.0692206
-----------------------------  -----------
2025-01-08 09:38:42 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:42 | [CL_point_env] epoch #0 | Pairwise Similarity Matrix: tensor([[ 1.0000, -1.0000],
        [-1.0000,  1.0000]], grad_fn=<MmBackward0>)
2025-01-08 09:38:42 | [CL_point_env] epoch #0 | Training Encoder

-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578852
PolicyTraining/MeanQ1Vals      -62.6757
PolicyTraining/MeanQ2Vals      -62.6757
PolicyTraining/MeanVVals       -62.2326
PolicyTraining/PolicyLoss       62.2317
PolicyTraining/QfLoss            0.0677262
PolicyTraining/VfLoss            0.0717044
-----------------------------  -----------
-----------------------------  -----------
Embedding/MeanContrastiveLoss    0.0578852
PolicyTraining/MeanQ1Vals      -62.6757
PolicyTraining/MeanQ2Vals      -62.6757
PolicyTraining/MeanVVals       -62.2326
PolicyTraining/PolicyLoss       62.2317
PolicyTraining/QfLoss            0.0677262
PolicyTraining/VfLoss            0.0717044
-----------------------------  -----------
2025-01-08 09:39:01 | [CL_point_env] epoch #0 | Evaluating...
2025-01-08 09:39:01 | [CL_point_env] epoch #0 | Sampling for adapation and meta-testing...


Failed to import TF-Keras. Please note that TF-Keras is not installed by default when you install TensorFlow Probability. This is so that JAX-only users do not have to install TensorFlow or TF-Keras. To use TensorFlow Probability with TensorFlow, please install the tf-keras or tf-keras-nightly package.
This can be be done through installing the tensorflow-probability[tf] extra.
/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.
  warnings.warn(


2025-01-08 09:39:02 | [CL_point_env] epoch #0 | Finished meta-testing...
2025-01-08 09:39:02 | [CL_point_env] epoch #0 | Sampling for adapation and meta-testing...


Failed to import TF-Keras. Please note that TF-Keras is not installed by default when you install TensorFlow Probability. This is so that JAX-only users do not have to install TensorFlow or TF-Keras. To use TensorFlow Probability with TensorFlow, please install the tf-keras or tf-keras-nightly package.
This can be be done through installing the tensorflow-probability[tf] extra.


2025-01-08 09:39:11 | [CL_point_env] epoch #0 | Finished meta-testing...
2025-01-08 09:39:11 | [CL_point_env] epoch #0 | Saving snapshot...
Traceback (most recent call last):
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/examples/torch/multi_env_CL.py", line 199, in <module>
    CL_point_env()
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/experiment.py", line 369, in __call__
    result = self.function(ctxt, **kwargs)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/examples/torch/multi_env_CL.py", line 196, in CL_point_env
    trainer.train(n_epochs=num_epochs, batch_size=batch_size)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 396, in train
    average_return = self._algo.train(self)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/torch/algos/CLMeta.py", line 286, in train
    for _ in trainer.step_epochs():
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 444, in step_epochs
    self.save(epoch)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 285, in save
    self._snapshotter.save_itr_params(epoch, params)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/snapshotter.py", line 125, in save_itr_params
    with open(file_name, 'wb') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/Users/paulnitschke/Desktop/projects/geo_meta_rl/data/local/experiment/CL_point_env_28/params.pkl'
Traceback (most recent call last):
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/examples/torch/multi_env_CL.py", line 199, in <module>
    CL_point_env()
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/experiment.py", line 369, in __call__
    result = self.function(ctxt, **kwargs)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/examples/torch/multi_env_CL.py", line 196, in CL_point_env
    trainer.train(n_epochs=num_epochs, batch_size=batch_size)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 396, in train
    average_return = self._algo.train(self)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/torch/algos/CLMeta.py", line 286, in train
    for _ in trainer.step_epochs():
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 444, in step_epochs
    self.save(epoch)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/trainer.py", line 285, in save
    self._snapshotter.save_itr_params(epoch, params)
  File "/Users/paulnitschke/Desktop/projects/geo_meta_rl/garage/experiment/snapshotter.py", line 125, in save_itr_params
    with open(file_name, 'wb') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/Users/paulnitschke/Desktop/projects/geo_meta_rl/data/local/experiment/CL_point_env_28/params.pkl'
